{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccfa6d08",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeeb21cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd0581",
   "metadata": {},
   "source": [
    "###### Some of the tests use realized variance and bipower variance. To avoid overlap, define a function that can be used for RV/BV calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af1b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realized_var(rt:np.array):\n",
    "    \"Calculate the realized variance of the returns\"\n",
    "    RV = np.sum(np.power(rt, 2))\n",
    "    return RV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fde1e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bipower_var(rt : np.array):\n",
    "    M = len(rt)\n",
    "    BV = (np.pi/2) * (M/(M-1)) * np.sum(np.abs(rt[1:] *np.abs(rt[:-1])))\n",
    "    return BV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec43ad05",
   "metadata": {},
   "source": [
    "# Tests based on squared variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe4b00",
   "metadata": {},
   "source": [
    "##### Barndorff-Nielsen and Shephard (2006) Test (BNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9db2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BNS(rt : np.array):\n",
    "    \"\"\"\n",
    "    Return the tests statistic defined in Barndorff-Nielsen and Shephard (2006)\n",
    "    \n",
    "    Code source : Maneesoonthorn, Worapree, Gael M. Martin, and Catherine S. Forbes. \n",
    "                  \"High-frequency jump tests: Which test should we use?.\" Journal of econometrics 219.2 (2020): 478-487.\n",
    "\n",
    "    \"\"\"\n",
    "    M = len(rt)\n",
    "    \n",
    "    RV = realized_var(rt)\n",
    "    BV = bipower_var(rt)\n",
    "    \n",
    "    constant = ((2**(2/3))*math.gamma(7/6)*(math.gamma(1/2)**(-1/2)))**(-3)\n",
    "    temp = np.sum(np.abs(rt[:-2])**(4/3) * np.abs(rt[1:-1])**(4/3) * np.abs(rt[2:])**(4/3))\n",
    "    \n",
    "    TP = constant * (M**2/(M-2)) * temp\n",
    "    \n",
    "    numerator = 1 - (BV/RV)\n",
    "    denumerator = np.sqrt(((np.pi/2)**2 + np.pi - 5) * M**-1 * max(1, (TP/BV**2)))\n",
    "    \n",
    "    test = numerator / denumerator\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef66700a",
   "metadata": {},
   "source": [
    "##### Corsi, Pirino, and Reno (2010) Test (CPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3c645c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPR(rt: np.array,K: int, c: int):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the tests statistic defined in Corsi, Pirino, and Reno (2010) \n",
    "    \n",
    "    \n",
    "    Code source : Maneesoonthorn, Worapree, Gael M. Martin, and Catherine S. Forbes. \n",
    "                  \"High-frequency jump tests: Which test should we use?.\" Journal of econometrics 219.2 (2020): 478-487.\n",
    "                  The authors used K = 10 and c = 3\n",
    "    \"\"\"\n",
    "    \n",
    "    M = len(rt)\n",
    "    RV = realized_var(rt)\n",
    "    \n",
    "    temp = np.multiply(np.abs(rt[:-1]), np.abs(rt[1:]))\n",
    "    Vti = np.zeros(M-K-1)\n",
    "    \n",
    "    for i in range(M-K-1):\n",
    "        Vti[i] = (np.pi/2) *(1/(K-1)) * np.sum(temp[i: i+K+1])\n",
    "    \n",
    "    psi = (c**2) * Vti\n",
    "    r = rt[K+1:]\n",
    "    \n",
    "    tau1 = np.where(r <= np.sqrt(psi), np.abs(r), 1.094*np.sqrt(psi))\n",
    "    tau43 = np.where(r <= np.sqrt(psi), np.abs(r)** (4/3), 1.129 * psi**(2/3))\n",
    "    \n",
    "    Mn = len(tau1) \n",
    "    CTBV = (np.pi/2) * (Mn / (Mn-1)) * np.sum(tau1[:-1] * tau1[1:])\n",
    "    constant = ((2**(2/3))*math.gamma(7/6)*(math.gamma(1/2)**(-1/2)))**(-3)\n",
    "    \n",
    "    temp2 = np.sum(tau43[0:-2]*tau43[1:-1]*tau43[2:])\n",
    "    CTPV = constant * (Mn**2 / (Mn-2)) * temp2\n",
    "    \n",
    "    numerator = 1 - (CTBV/RV)\n",
    "    denumerator = ((np.pi/2) **2 + np.pi - 5) * (1/Mn) * max(1, CTPV/CTBV**2)\n",
    "    \n",
    "    test = numerator / np.sqrt(denumerator)\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6f9734",
   "metadata": {},
   "source": [
    "##### Andersen, Dobrev, and Schaumburg (2009) Tests Based on MinRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd8dd7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TMIN(rt : np.array):  \n",
    "    \"\"\"\n",
    "    Andersen, Dobrev, and Schaumburg (2009)\n",
    "    \n",
    "    Code source : Maneesoonthorn, Worapree, Gael M. Martin, and Catherine S. Forbes. \n",
    "                  \"High-frequency jump tests: Which test should we use?.\" Journal of econometrics 219.2 (2020): 478-487.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Length of the (log) return series\n",
    "    M = len(rt)\n",
    "    \n",
    "    #Calculate realized variance\n",
    "    RV = realized_var(rt)\n",
    "    \n",
    "    temp = np.minimum(np.abs(rt[1:]),np.abs(rt[:-1]))\n",
    "    MinRV = (np.pi/(np.pi-2))*(M/(M-1)) *np.sum(temp**2)\n",
    "    \n",
    "    MinRQ = (np.pi/(3*np.pi-8))* (M**2/(M-1)) *np.sum(temp**4)\n",
    "    \n",
    "    numerator = 1 - (MinRV/RV)\n",
    "    denumerator = np.sqrt(1.81/M) * max(1,(MinRQ/(MinRV**2)))\n",
    "\n",
    "    test = numerator / denumerator\n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc989f72",
   "metadata": {},
   "source": [
    "##### Andersen, Dobrev, and Schaumburg (2009) Tests Based on MedRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "868eb6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TMED(rt : np.array):\n",
    "    \"\"\"\n",
    "    Andersen, Dobrev, and Schaumburg (2009)\n",
    "    \n",
    "    Code source : Maneesoonthorn, Worapree, Gael M. Martin, and Catherine S. Forbes. \n",
    "                  \"High-frequency jump tests: Which test should we use?.\" Journal of econometrics 219.2 (2020): 478-487.\n",
    "    \"\"\"\n",
    "    M = len(rt)\n",
    "    RV = realized_var(rt)\n",
    "    data_med = np.stack([np.abs(rt[0:M-2]), np.abs(rt[1:M-1]), np.abs(rt[2:])])\n",
    "    constant_medrv = np.pi /(np.pi + 6 - 4*np.sqrt(3)) * (M/(M-2))\n",
    "    MedRV = constant_medrv * np.sum(np.median(data_med, axis = 0)**2)\n",
    "    \n",
    "    constant_medrq = 3*np.pi/(9*np.pi + 72 - 52*np.sqrt(3)) * (M**2/(M-2))\n",
    "    MedRQ = constant_medrq * np.sum(np.median(data_med,axis = 0)**4)\n",
    "    \n",
    "    numerator = 1 - (MedRV/RV)\n",
    "    denumerator = np.sqrt(0.96/M *max(1,(MedRQ/MedRV**2)))\n",
    "    test = numerator / denumerator\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0ffff0",
   "metadata": {},
   "source": [
    "## Tests based on P-power variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20665cf",
   "metadata": {},
   "source": [
    "##### Podolskij and Ziggel (2010) Test (Two variations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bc4a975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PZ2(rt : np.array, tau: int):\n",
    "    \"\"\"\n",
    "    Podolskij and Ziggel (2010) \n",
    "    \n",
    "    Code source : Maneesoonthorn, Worapree, Gael M. Martin, and Catherine S. Forbes. \n",
    "                  \"High-frequency jump tests: Which test should we use?.\" Journal of econometrics 219.2 (2020): 478-487.\n",
    "    Tau?\n",
    "    \"\"\"\n",
    "    M = len(rt)\n",
    "    BV = bipower_var(rt)\n",
    "    trunc = 2.3 * np.sqrt(BV) * ((1/M)**(0.4))\n",
    "\n",
    "    unif = np.random.uniform(size = M)\n",
    "    eta = np.where(unif <= 0.5, 1-tau, 1+tau)\n",
    "\n",
    "    Bhat2 = np.sqrt(M) * np.sum(np.abs(rt)**2 * (1 - eta *np.where(np.abs(rt) < trunc, 1, 0)))\n",
    "    Vbar4 = M * np.sum(np.where(np.abs(rt) < trunc,rt **4,0))\n",
    "    var2 = np.var(eta) * Vbar4\n",
    "    \n",
    "    test = Bhat2/np.sqrt(var2)\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2c311266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PZ4(rt : np.array, tau: int):\n",
    "    \"\"\"\n",
    "    Podolskij and Ziggel (2010) \n",
    "    \n",
    "    Code source : Maneesoonthorn, Worapree, Gael M. Martin, and Catherine S. Forbes. \n",
    "                  \"High-frequency jump tests: Which test should we use?.\" Journal of econometrics 219.2 (2020): 478-487.\n",
    "    Tau?\n",
    "    \"\"\"\n",
    "    M = len(rt)\n",
    "    BV = bipower_var(rt)\n",
    "    trunc = 2.3 * np.sqrt(BV) * ((1/M)**(0.4))\n",
    "\n",
    "    unif = np.random.uniform(size = M)\n",
    "    eta = np.where(unif <= 0.5, 1-tau, 1+tau)\n",
    "\n",
    "    Bhat4 =M**(3/2) * np.sum(np.abs(rt)**4 * (1 - eta *np.where(np.abs(rt) < trunc, 1, 0)))\n",
    "    Vbar8 = M**3 * np.sum(np.where(np.abs(rt) < trunc,rt **8,0))\n",
    "    var4 = np.var(eta) * Vbar8\n",
    "    \n",
    "    test = Bhat4/np.sqrt(var4)\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3356081",
   "metadata": {},
   "source": [
    "##### The Ait-Sahalia and Jacod (2008) Test (ASJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b2862460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ASJ(rt : np.array):\n",
    "    \"\"\"\n",
    "    Ait-Sahalia and Jacod (2008) \n",
    "    \n",
    "    Code source : Maneesoonthorn, Worapree, Gael M. Martin, and Catherine S. Forbes. \n",
    "                  \"High-frequency jump tests: Which test should we use?.\" Journal of econometrics 219.2 (2020): 478-487.\n",
    "    \"\"\"\n",
    "    M = len(rt)\n",
    "    K= 3\n",
    "    temp = np.multiply(np.abs(rt[:-1]), np.abs(rt[1:]))\n",
    "    Vti = np.zeros(M-K-1)\n",
    "    \n",
    "    for i in range(M-K-1):\n",
    "        Vti[i] = (np.pi/2) *(1/(K-1)) * np.sum(temp[i: i+K+1])\n",
    "\n",
    "    mp = 3\n",
    "    m2p = 105\n",
    "    Mpk = (16 * 2) * (2*4-2-1)/3\n",
    "\n",
    "    tempr = rt[M-len(Vti):M]\n",
    "    #Define M for further calculation\n",
    "    M = len(tempr)\n",
    "    rtk = tempr[1::2]\n",
    "    \n",
    "    Bhat = np.sum(np.abs(np.power(tempr,4)))\n",
    "    Bhatk = np.sum(np.abs(np.power(rtk,4)))\n",
    "    Shat = Bhat / Bhatk\n",
    "    \n",
    "    trunc = 3*np.sqrt(Vti*M)*((1/M)**0.48)\n",
    "    Ahat = (M/mp) * np.sum(np.abs(np.power(tempr,4)) * np.where(np.abs(tempr) < trunc,1,0))\n",
    "    Ahat2 = ((M**3)/m2p) * np.sum(np.abs(np.power(tempr,8)) * np.where(np.abs(tempr) < trunc,1,0))\n",
    "    \n",
    "    Sig = (1/M) * Mpk * Ahat2 / (Ahat**2)\n",
    "    test = (Shat - 2) /np.sqrt(Sig)\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8744fa80",
   "metadata": {},
   "source": [
    "# Data Generating Process\n",
    "Based on Maneesoonthorn (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18a6d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGP_Maneesoonthorn(mu = 0,kappa = 5, rho = -0.5, theta = 0.16, sigma_v = 0.5, sec = 300):\n",
    "\n",
    "    dt = 1/21600\n",
    "\n",
    "    #Generate multivariate normal variables\n",
    "    W = np.random.multivariate_normal(mean = [0, 0],\n",
    "                                      cov = [[dt,dt* rho],[dt* rho,dt]],\n",
    "                                      size = 21600)\n",
    "\n",
    "    #Define the stepsize\n",
    " \n",
    "    #Generate the volatility process\n",
    "    v = np.zeros(21600)\n",
    "    #First value equals as per the paper\n",
    "    v[0] = theta\n",
    "    \n",
    "    #Define the mean reversion parameter / Use one of Dimitru's value\n",
    "\n",
    "    for i in range(1,21600):\n",
    "        #The multiplier of sqrt(dt) comes from the discretization of a Brownian motion\n",
    "        v[i] =  v[i-1] + kappa * (theta - v[i - 1] ) * dt + sigma_v * np.sqrt(v[i-1]) * W[i,0] \n",
    "\n",
    "    #Generate the returns\n",
    "    \n",
    "    r = np.zeros(21600)\n",
    "    for i in range(21600):\n",
    "        r[i] = mu * dt + np.sqrt(v[i]) *  W[i,1]\n",
    "\n",
    "    #Take the cummulative sum of the return process and take every \"sec\" th element\n",
    "    r = np.add.reduceat(r, np.arange(0,len(r),sec))\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf34abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGP_SV1F(alpha = -0.100, corr = -0.62):\n",
    "    \"\"\"\n",
    "    This DGP is based on the SV1F proposed in Dumitru and Urga (2012). The correlation parameter is fixed \n",
    "    at -0.62 in the original paper,however for parameter alpha 3 different values were used. This way we \n",
    "    only simulate the continuous part, that is used for example in the test size analysis.\n",
    "\n",
    "    Output - np.array of length 72\n",
    "    \"\"\"\n",
    "\n",
    "    #Generate multivariate normal variables\n",
    "    W = np.random.multivariate_normal(mean = [0, 0],\n",
    "                                      cov = [[1,-0.62],[-0.62,1]],\n",
    "                                      size = 21600)\n",
    "\n",
    "    #Define the stepsize\n",
    "    dt = 1/21600\n",
    "\n",
    "    #Generate the volatility process\n",
    "    v = np.zeros(21600)\n",
    "    v[0] = (0.16)\n",
    "    #Define the mean reversion parameter / Use one of Dimitru's value\n",
    "    alpha = -0.100\n",
    "    for i in range(1,21600):\n",
    "        #The multiplier of sqrt(dt) comes from the discretization of a Brownian motion\n",
    "        v[i] = v[i - 1] + alpha * v[i - 1]*dt + np.sqrt(dt) * W[i,0]\n",
    "\n",
    "    #Generate the price process\n",
    "    p = np.zeros(21600)\n",
    "    for i in range(21600):\n",
    "        p[i] = 0.03 * dt + np.exp(0.125 * v[i]) * np.sqrt(dt) * W[i,1]\n",
    "\n",
    "    #Take the cummulative sum of the price process and take every 300th element\n",
    "    p = np.add.reduceat(p, np.arange(0,len(p),300))\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37d648",
   "metadata": {},
   "source": [
    "# Testing Area\n",
    "The 5 minute inverval is examined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6eec72",
   "metadata": {},
   "source": [
    "## Compare to Maneesoonthorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7c0a41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000 #number of simulations\n",
    "\n",
    "#Define lists to save results\n",
    "ered_BNS = np.array([])\n",
    "ered_cpr = np.array([])\n",
    "ered_min = np.array([])\n",
    "ered_med = np.array([])\n",
    "ered_pz2 = np.array([])\n",
    "ered_pz4 = np.array([])\n",
    "ered_asj = np.array([])\n",
    "\n",
    "for i in range(n):\n",
    "    #Simulate rt\n",
    "    r = DGP_Maneesoonthorn()\n",
    "        \n",
    "    #Calculate test stat and save to list\n",
    "    test_BNS = BNS(r)\n",
    "    ered_BNS = np.append(ered_BNS, test_BNS)\n",
    "    \n",
    "    test_cpr = CPR(r, 10,3)\n",
    "    ered_cpr = np.append(ered_cpr, test_cpr)\n",
    "    \n",
    "    test_min = TMIN(r)\n",
    "    ered_min = np.append(ered_min, test_min)\n",
    "    \n",
    "    test_med = TMED(r)\n",
    "    ered_med = np.append(ered_med, test_med)\n",
    "\n",
    "    test_pz2 = PZ2(r,0.1)\n",
    "    ered_pz2 = np.append(ered_pz2, test_pz2)\n",
    "\n",
    "    test_pz4 = PZ4(r,0.1)\n",
    "    ered_pz4 = np.append(ered_pz4, test_pz4)\n",
    "    \n",
    "    test_asj = ASJ(r)\n",
    "    ered_asj = np.append(ered_asj, test_asj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "60de70b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Size of BNS: 0.073. Original size : 0.055'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size of CPR: 0.484. Original size : 0.464'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size of TMIN: 0.053. Original size : 0.044'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size of TMED: 0.059. Original size : 0.060'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size of PZ2: 0.119. Original size : 0.092'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size of PZ4: 0.116. Original size : 0.078'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size of ASJ: 0.0. Original size : 0.000'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparing to Maneesoonthorn\n",
    "display(f\"Size of BNS: {np.sum(ered_BNS >= 1.644854)/n}. Original size : 0.055\")\n",
    "display(f\"Size of CPR: {np.sum(ered_cpr >= 1.644854)/n}. Original size : 0.464\")\n",
    "display(f\"Size of TMIN: {np.sum(ered_min >= 1.644854)/n}. Original size : 0.044\")\n",
    "display(f\"Size of TMED: {np.sum(ered_med >= 1.644854)/n}. Original size : 0.060\")\n",
    "display(f\"Size of PZ2: {np.sum(ered_pz2 >= 1.644854)/n}. Original size : 0.092\")\n",
    "display(f\"Size of PZ4: {np.sum(ered_pz4 >= 1.644854)/n}. Original size : 0.078\")\n",
    "display(f\"Size of ASJ: {np.sum(ered_asj <= -1.644854)/n}. Original size : 0.000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e15d2b",
   "metadata": {},
   "source": [
    "## Compare to Dimitru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4f55e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000 #number of simulations\n",
    "\n",
    "#Define lists to save results\n",
    "ered_BNS = np.array([])\n",
    "ered_cpr = np.array([])\n",
    "ered_min = np.array([])\n",
    "ered_med = np.array([])\n",
    "ered_pz2 = np.array([])\n",
    "ered_pz4 = np.array([])\n",
    "ered_asj = np.array([])\n",
    "\n",
    "for i in range(n):\n",
    "    #Simulate rt\n",
    "    r = DGP_SV1F()\n",
    "        \n",
    "    #Calculate test stat and save to list\n",
    "    test_BNS = BNS(r)\n",
    "    ered_BNS = np.append(ered_BNS, test_BNS)\n",
    "    \n",
    "    test_cpr = CPR(r, 10,3)\n",
    "    ered_cpr = np.append(ered_cpr, test_cpr)\n",
    "    \n",
    "    test_min = TMIN(r)\n",
    "    ered_min = np.append(ered_min, test_min)\n",
    "    \n",
    "    test_med = TMED(r)\n",
    "    ered_med = np.append(ered_med, test_med)\n",
    "\n",
    "    test_pz2 = PZ2(r,0.1)\n",
    "    ered_pz2 = np.append(ered_pz2, test_pz2)\n",
    "\n",
    "    test_pz4 = PZ4(r,0.1)\n",
    "    ered_pz4 = np.append(ered_pz4, test_pz4)\n",
    "    \n",
    "    test_asj = ASJ(r)\n",
    "    ered_asj = np.append(ered_asj, test_asj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6f672fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Size of BNS: 0.057. Original size : 0.053'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size of CPR: 0.441. Original size : 0.056'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size of TMIN: 0.042. Original size : 0.044'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size of TMED: 0.055. Original size : 0.052'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size of PZ2: 0.082. Original size : 0.083'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size of PZ4: 0.082. Original size : 0.083'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Size of ASJ: 0.0. Original size : 0.031 - 0.051'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Comparing to Dimitru\n",
    "display(f\"Size of BNS: {np.sum(ered_BNS >= 1.644854)/n}. Original size : 0.053\")\n",
    "display(f\"Size of CPR: {np.sum(ered_cpr >= 1.644854)/n}. Original size : 0.056\")\n",
    "display(f\"Size of TMIN: {np.sum(ered_min >= 1.644854)/n}. Original size : 0.044\")\n",
    "display(f\"Size of TMED: {np.sum(ered_med >= 1.644854)/n}. Original size : 0.052\")\n",
    "display(f\"Size of PZ2: {np.sum(ered_pz2 >= 1.644854)/n}. Original size : 0.083\")\n",
    "display(f\"Size of PZ4: {np.sum(ered_pz4 >= 1.644854)/n}. Original size : 0.083\")\n",
    "display(f\"Size of ASJ: {np.sum(ered_asj <= -1.644854)/n}. Original size : 0.031 - 0.051\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
